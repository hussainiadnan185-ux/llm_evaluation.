{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-YkEC-uu2QB"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install transformers torch pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y-Bp-0yLvVrY"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "prompts = [\n",
        "    \"Who is the missile man of India?\",\n",
        "    \"What is AI and ML?\",\n",
        "    \"Name the 7 wonders of the world.\",\n",
        "    \"Name the female who won two Nobel Prizes.\",\n",
        "    \"How many females have won more than one Nobel Prize?\",\n",
        "    \"Explain AI and ML in the simplest terms.\",\n",
        "    \"Explain what a data analyst actually does in the simplest terms.\"\n",
        "]\n",
        "\n",
        "models = {\n",
        "    \"phi3_mini\": pipeline(\n",
        "        \"text-generation\",\n",
        "        model=\"microsoft/Phi-3-mini-4k-instruct\",\n",
        "        device=0\n",
        "    ),\n",
        "    \"distilgpt2\": pipeline(\n",
        "        \"text-generation\",\n",
        "        model=\"distilgpt2\",\n",
        "        device=0\n",
        "    )\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    for prompt in prompts:\n",
        "        start_time = time.time()\n",
        "\n",
        "        output = model(\n",
        "            prompt,\n",
        "            max_new_tokens=30,\n",
        "            do_sample=False,\n",
        "            return_full_text=False\n",
        "        )\n",
        "\n",
        "        end_time = time.time()\n",
        "        response_text = output[0][\"generated_text\"]\n",
        "\n",
        "        results.append({\n",
        "            \"model_name\": model_name,\n",
        "            \"prompt\": prompt,\n",
        "            \"response\": response_text,\n",
        "            \"latency_seconds\": round(end_time - start_time, 3),\n",
        "            \"response_length\": len(response_text)\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"llm_evaluation_results.csv\", index=False)\n",
        "\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMxODmvlvVye"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1t-IvruvV4g"
      },
      "outputs": [],
      "source": [
        "df.groupby(\"model_name\")[[\"latency_seconds\", \"response_length\"]].mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2jeMrq_xRNl"
      },
      "source": [
        "## Observations\n",
        "\n",
        "- distilgpt2 was significantly faster but failed to handle instruction-based prompts, producing incoherent or repetitive outputs.\n",
        "- Phi-3 Mini generated more coherent and informative responses, though with higher latency.\n",
        "- This highlights the trade-off between response quality and inference speed when selecting language models.\n",
        "- For instruction-heavy tasks such as Q&A, instruction-tuned models are more suitable than base language models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE_DJidjxVaM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}